{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *Datasets*\n",
    "\n",
    "Os *datasets* (conjuntos de dados) são o principal insumo dos processos de análise de dados e de ciência de dados. Eles são representados normalmente por dados tabulares em formato de planilha onde as linhas são os registros dos acontecimentos e as colunas são as características desses acontecimentos.\n",
    "\n",
    "Existem variadas formas de salvar um *dataset*, na área de processamento de dados as formas mais comuns envolvem salvar os dados em arquivos nos formatos `.xlsx`, `.csv` ou `.tsv`. Embora também seja possível trabalhar com dados guardados em bases de dados, obtendo as informações por meio de consultas a base.\n",
    "\n",
    "Neste `notebook` será apresentado o carregamento do *dataset*  [*DETECTING INDIVIDUAL AND COMBINED FINGERS MOVEMENTS*](https://www.rami-khushaba.com/electromyogram-emg-repository.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detalhes do *dataset*\n",
    ">É uma boa prática prover um resumo do *dataset* utilizado, pontuando características importantes para o processo da analise dos dados, explicando como ele está estruturado e colocando as devidas refências quando aplicável.\n",
    "\n",
    "*dataset*: DETECTING INDIVIDUAL AND COMBINED FINGERS MOVEMENTS \\[1\\]\n",
    "\n",
    "\n",
    "Dez sujeitos, com idade entre 20 e 35 anos foram recrutados para realizarem movimentos com os dedos.\n",
    "Os sujeitos possuem os membros normais e sem desordem neurológica ou muscular. Os sujeitos estavam sentados em uma poltrona com o braço apoiado e fixado em uma posição, para evitar efeitos de posições diferentes do membro. Os dados foram coletados utilizando **2 canais EMG** e processados pelo software Bagnoli Desktop EMG Systems da Delsys Inc. Os sinals EMG coletados dos eletrodos foram amplificados utilizando o amplificador Delsys Bagnoli-8 para um ganho total de 1000. Um conversor analógico digital de 12 bits foi utilizado para amostrar o sinal a **4000 Hz**.\n",
    "\n",
    "Os sinais EMG foram filtrados por um filtro passa-banda entre 20 e 450 Hz com um filtro *notch* para remover as faixas de 50 Hz provenientes da rede elétrica.\n",
    "Sinais de dez classes de movimentos de dedos, individuais e combinados, foram coletados. Para cada classe foram realizados seis ensaios.\n",
    "\n",
    "- Flexão individual:\n",
    "  - Polegar (T-T)\n",
    "  - Indicador (I-I)\n",
    "  - Médio (M-M)\n",
    "  - Anular (R-R)\n",
    "  - Minimo (L-L)\n",
    "\n",
    "- Flexão combinada:\n",
    "  - Polegar-Indicador (T-I)\n",
    "  - Polegar-Médio (T-M)\n",
    "  - Polegar-Anular (T-R)\n",
    "  - Polegar-Minimo (T-L)\n",
    "  - Punho fechado (HC)\n",
    "\n",
    "Os arquivos do *dataset* estão organizados da seguinte forma: há uma pasta para cada sujeito, o padrão de nomenclatura das pastas é `EMG-S<número_do_sujeito>`, por exemplo, para o sujeito 1 temos a pasta\n",
    " `EMG-S1`, para o sujeito 2 temos a pasta `EMG-S2`, e assim sucessivamente.\n",
    "\n",
    "Dentro de cada pasta há um arquivo `.csv` para cada coleta. São seis ensaios por classe, totalizando 60 arquivos `.csv`. Cada arquivo possui duas colunas, sem cabeçalho. Cada coluna representa os dados de um canal EMG. A nomenclatura dos arquivos segue o padrão `<nome_da_classe><número_da_coleta>.csv`, por exemplo, a primeira coleta do arquivo da classe Polegar, representado por T-T, tem o nome `T-T1.csv`, o arquivo da segunda coleta tem o nome `T-T2.csv`, e assim sucessivamente.\n",
    "\n",
    "\\[1\\] R. N. Khushaba, M. Takruri, S. Kodagoda, and G. Dissanayake, \"Toward Improved Control of Prosthetic Fingers Using Surface Electromyogram (EMG) Signals\", Expert Systems with Applications, vol 39, no. 12, pp. 10731–10738, 2012.\n",
    "Disponível em: (https://www.rami-khushaba.com/electromyogram-emg-repository.html)\n",
    "\n",
    "\n",
    ">Com a análise dos detalhes do *dataset* utilizado descobrimos dados importantes, como a frêquencia de amostragem e o fato de que esse *dataset* já teve seus dados filtratos para remoção de interferências da rede elétrica. Estas informações serão úteis em etapas posteriores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregando o *dataset*\n",
    "\n",
    "O carregamento do *dataset* varia conforme o formato que os dados estão armazenados e estruturados. Vimos que temos os dados no formato `.csv`, utilizaremos a biblioteca [pandas](https://pandas.pydata.org) para realizar o carregamento e a biblioteca [numpy](https://numpy.org) para organizar os dados em arrays para facilitar a manipulação destes dados futuramente.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  0         1\n",
      "0     -3.588744e-04 -0.000056\n",
      "1     -3.778360e-04 -0.000065\n",
      "2     -3.917736e-04 -0.000067\n",
      "3     -3.930701e-04 -0.000051\n",
      "4     -3.933943e-04 -0.000023\n",
      "...             ...       ...\n",
      "19995 -1.028112e-04 -0.000007\n",
      "19996 -6.018800e-05  0.000018\n",
      "19997 -6.176923e-08  0.000051\n",
      "19998  6.784360e-05  0.000087\n",
      "19999  1.299146e-04  0.000115\n",
      "\n",
      "[20000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# carrega um arquivo .csv para um pandas dataframe\n",
    "t_t1 = pd.read_csv('./lib/data/EMG_2Chs/EMG-S1/T-T1.csv', delimiter=',', header=None)\n",
    "\n",
    "# imprime o dataframe\n",
    "print(t_t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 2)\n"
     ]
    }
   ],
   "source": [
    "# converte o dataframe do pandas para um numpy array\n",
    "t_t1 = t_t1.to_numpy()\n",
    "\n",
    "# imprime o shape do numpy array\n",
    "print(t_t1.shape)\n",
    "# neste exemplo devemos ter um shape de (20000, 2), 20000 linhas e 2 colunas, onde cada coluna é um canal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Realizamos o carregamento de um ensaio de uma classe de um sujeito e o tranformamos em um numpy array. É preciso carregar todas os ensaios de cada classe, podemos usufluir do padrão da nomenclaruta dos arquivos e criar um laço de repetição para o carregamento destes dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 6, 20000, 2) - (classes, ensaios, linhas, canais)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "classes = ['T-I','T-L','T-M','T-R','T-T','HC-','I-I','L-L','M-M','R-R']\n",
    "\n",
    "# variável para armazenar os dados das classes\n",
    "data = []\n",
    "\n",
    "for classe in classes:\n",
    "    # variável para armazear os dados dos ensaios\n",
    "    trials = []\n",
    "    for i in range(1, 7): # de 1 a 6 (Qt. de ensaios)\n",
    "        # carrega o arquivo .csv para um pandas dataframe\n",
    "        dataframe = pd.read_csv(f'./lib/data/EMG_2Chs/EMG-S1/{classe}{i}.csv', delimiter=',', header=None)\n",
    "        \n",
    "        # converte os dados do um ensaio para numpy array e o adiciona na lista de ensaios\n",
    "        trials.append(dataframe.to_numpy())\n",
    "    \n",
    "    # adiciona os ensaios de uma classe a lista de dados das classes\n",
    "    data.append(trials)\n",
    "\n",
    "# transforma os dados das classes em um numpy array\n",
    "data = np.array(data)\n",
    "\n",
    "# imprime o shape do numpy array\n",
    "print(f'{data.shape} - (classes, ensaios, linhas, canais)')\n",
    "# neste momento devemos ter um shape de (10, 6, 20000, 2), sendo 10 classes, 6 ensaios, 20000 linhas e 2 canais\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O shape atual dos dados não é adequado para os processamentos posterior que serão aplicados sobre eles, o ideal é que as linhas com os dados dos eletrodos estejam no último eixo do numpy array, para corrigir isso podemos utilizar a função *swapaxes* do próprio numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 6, 2, 20000) - (classes, ensaios, canais, linhas)\n"
     ]
    }
   ],
   "source": [
    "# troca os eixos 2 e 3 do numpy array\n",
    "data = data.swapaxes(2, 3)\n",
    "\n",
    "# imprime o shape do numpy array\n",
    "print(f'{data.shape} - (classes, ensaios, canais, linhas)')\n",
    "# neste momento devemos ter um shape de (10, 6, 2, 2000), sendo 10 classes, 6 ensaios, 2 canais e 20000 linhas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Desafio:** Utilizando o padrão de nomenclatura das pastas que guardam os arquivos do *dataset*, implemente uma função que realizará o carregamento dos dados para todas os sujeitos do *dataset*. Essa função deve retornar um dicionário python cuja as chaves sejam os sujeitos e o valor de cada chave seja um numpy array representando os dados daquele sujeito."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sua função aqui"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Melhorando o carregamento dos dados\n",
    "\n",
    "Durante o desenvolvimento de uma analise de dados é comum precisar rodar o código várias vezes, sendo ncessário carregar sempre os dados dos arquivos do *dataset* e realizar a conversão para numpy array.\n",
    "É possível, entretando, salvar os dados do numpy array em um arquivo `.npy`, desta forma sempre que o código for executado podemos verificar se o arquivo já existe e realizar um rápido carregamento dos dados já no formato numpy array, sem a necessidade de carregar os arquivos do *dataset* e realizar conversões."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.0002476975\n"
     ]
    }
   ],
   "source": [
    "# Salva o numpy array 'data' em './lib/data/converted/s1.npy'\n",
    "np.save('./lib/data/converted/s1', data)\n",
    "print(np.load('./lib/data/converted/s1.npy'))\n",
    "# Lembre-se de que o diretório deve existir, caso contrário uma exceção será lançada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Desafio:** Implemente uma função que carregue os dados de todos os sujeitos do *dataset*. Para cada sujeito a função deve verificar a existencia de um arquivo `.npy`, caso o arquivo exista ele deve ser carregado, caso contrário um carregamento dos arquivos do *dataset* deve ser realizado, salvando os dados em uma arquivo `.npy` ao final. Essa função deve retornar um dicionário python contendo os dados de todos os sujeitos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sua função aqui"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Desafio:** Escolha junto com seu professor um *dataset* de EMG e implemente uma função que retorne todos os dados deste *dataset* em um numpy array, lembrando de implementar a funcionalidade de salvar e carregar os dados do numpy array nos arquivos `.npy`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
